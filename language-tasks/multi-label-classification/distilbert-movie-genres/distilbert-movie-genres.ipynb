{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_cleanup(df): # data cleanup code credit: Vladislav Kolesov\n",
    "    df['genres']=df['Genre'] \n",
    "    df['genres']=df['genres'].str.strip()\n",
    "    df['genres']=df['genres'].str.replace(' - ', '|')\n",
    "    df['genres']=df['genres'].str.replace(' / ', '|')\n",
    "    df['genres']=df['genres'].str.replace('/', '|')\n",
    "    df['genres']=df['genres'].str.replace(' & ', '|')\n",
    "    df['genres']=df['genres'].str.replace(', ', '|')\n",
    "    df['genres']=df['genres'].str.replace('; ', '|')\n",
    "    df['genres']=df['genres'].str.replace('bio-pic', 'biography')\n",
    "    df['genres']=df['genres'].str.replace('biopic', 'biography')\n",
    "    df['genres']=df['genres'].str.replace('biographical', 'biography')\n",
    "    df['genres']=df['genres'].str.replace('biodrama', 'biography')\n",
    "    df['genres']=df['genres'].str.replace('bio-drama', 'biography')\n",
    "    df['genres']=df['genres'].str.replace('biographic', 'biography')\n",
    "    df['genres']=df['genres'].str.replace(' \\(film genre\\)', '')\n",
    "    df['genres']=df['genres'].str.replace('animated','animation')\n",
    "    df['genres']=df['genres'].str.replace('anime','animation')\n",
    "    df['genres']=df['genres'].str.replace('children\\'s','children')\n",
    "    df['genres']=df['genres'].str.replace('comedey','comedy')\n",
    "    df['genres']=df['genres'].str.replace('\\[not in citation given\\]','')\n",
    "    df['genres']=df['genres'].str.replace(' set 4,000 years ago in the canadian arctic','')\n",
    "    df['genres']=df['genres'].str.replace('historical','history')\n",
    "    df['genres']=df['genres'].str.replace('romantic','romance')\n",
    "    df['genres']=df['genres'].str.replace('3-d','animation')\n",
    "    df['genres']=df['genres'].str.replace('3d','animation')\n",
    "    df['genres']=df['genres'].str.replace('viacom 18 motion pictures','')\n",
    "    df['genres']=df['genres'].str.replace('sci-fi','science_fiction')\n",
    "    df['genres']=df['genres'].str.replace('ttriller','thriller')\n",
    "    df['genres']=df['genres'].str.replace('.','')\n",
    "    df['genres']=df['genres'].str.replace('based on radio serial','')\n",
    "    df['genres']=df['genres'].str.replace(' on the early years of hitler','')\n",
    "    df['genres']=df['genres'].str.replace('sci fi','science_fiction')\n",
    "    df['genres']=df['genres'].str.replace('science fiction','science_fiction')\n",
    "    df['genres']=df['genres'].str.replace(' (30min)','')\n",
    "    df['genres']=df['genres'].str.replace('16 mm film','short')\n",
    "    df['genres']=df['genres'].str.replace('\\[140\\]','drama')\n",
    "    df['genres']=df['genres'].str.replace('\\[144\\]','')\n",
    "    df['genres']=df['genres'].str.replace(' for ','')\n",
    "    df['genres']=df['genres'].str.replace('adventures','adventure')\n",
    "    df['genres']=df['genres'].str.replace('kung fu','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('kung-fu','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('martial arts','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('world war ii','war')\n",
    "    df['genres']=df['genres'].str.replace('world war i','war')\n",
    "    df['genres']=df['genres'].str.replace('biography about montreal canadiens star|maurice richard','biography')\n",
    "    df['genres']=df['genres'].str.replace('bholenath df|cinekorn entertainment','')\n",
    "    df['genres']=df['genres'].str.replace(' \\(volleyball\\)','')\n",
    "    df['genres']=df['genres'].str.replace('spy film','spy')\n",
    "    df['genres']=df['genres'].str.replace('anthology film','anthology')\n",
    "    df['genres']=df['genres'].str.replace('biography fim','biography')\n",
    "    df['genres']=df['genres'].str.replace('avant-garde','avant_garde')\n",
    "    df['genres']=df['genres'].str.replace('biker film','biker')\n",
    "    df['genres']=df['genres'].str.replace('buddy cop','buddy')\n",
    "    df['genres']=df['genres'].str.replace('buddy film','buddy')\n",
    "    df['genres']=df['genres'].str.replace('comedy 2-reeler','comedy')\n",
    "    df['genres']=df['genres'].str.replace('films','')\n",
    "    df['genres']=df['genres'].str.replace('film','')\n",
    "    df['genres']=df['genres'].str.replace('biography of pioneering american photographer eadweard muybridge','biography')\n",
    "    df['genres']=df['genres'].str.replace('british-german co-production','')\n",
    "    df['genres']=df['genres'].str.replace('bruceploitation','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('comedy-drama adaptation of the mordecai richler novel','comedy-drama')\n",
    "    df['genres']=df['genres'].str.replace('df by the mob\\|knkspl','')\n",
    "    df['genres']=df['genres'].str.replace('df','')\n",
    "    df['genres']=df['genres'].str.replace('movie','')\n",
    "    df['genres']=df['genres'].str.replace('coming of age','coming_of_age')\n",
    "    df['genres']=df['genres'].str.replace('coming-of-age','coming_of_age')\n",
    "    df['genres']=df['genres'].str.replace('drama about child soldiers','drama')\n",
    "    df['genres']=df['genres'].str.replace('(( based).+)','')\n",
    "    df['genres']=df['genres'].str.replace('(( co-produced).+)','')\n",
    "    df['genres']=df['genres'].str.replace('(( adapted).+)','')\n",
    "    df['genres']=df['genres'].str.replace('(( about).+)','')\n",
    "    df['genres']=df['genres'].str.replace('musical b','musical')\n",
    "    df['genres']=df['genres'].str.replace('animationchildren','animation|children')\n",
    "    df['genres']=df['genres'].str.replace(' period','period')\n",
    "    df['genres']=df['genres'].str.replace('drama loosely','drama')\n",
    "    df['genres']=df['genres'].str.replace(' \\(aquatics|swimming\\)','')\n",
    "    df['genres']=df['genres'].str.replace(' \\(aquatics|swimming\\)','')\n",
    "    df['genres']=df['genres'].str.replace(\"yogesh dattatraya gosavi's directorial debut \\[9\\]\",'')\n",
    "    df['genres']=df['genres'].str.replace(\"war-time\",\"war\")\n",
    "    df['genres']=df['genres'].str.replace(\"wartime\",\"war\")\n",
    "    df['genres']=df['genres'].str.replace(\"ww1\",\"war\")\n",
    "    df['genres']=df['genres'].str.replace('unknown','')\n",
    "    df['genres']=df['genres'].str.replace(\"wwii\",\"war\")\n",
    "    df['genres']=df['genres'].str.replace('psychological','psycho')\n",
    "    df['genres']=df['genres'].str.replace('rom-coms','romance')\n",
    "    df['genres']=df['genres'].str.replace('true crime','crime')\n",
    "    df['genres']=df['genres'].str.replace('\\|007','')\n",
    "    df['genres']=df['genres'].str.replace('slice of life','slice_of_life')\n",
    "    df['genres']=df['genres'].str.replace('computer animation','animation')\n",
    "    df['genres']=df['genres'].str.replace('gun fu','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('j-horror','horror')\n",
    "    df['genres']=df['genres'].str.replace(' \\(shogi|chess\\)','')\n",
    "    df['genres']=df['genres'].str.replace('afghan war drama','war drama')\n",
    "    df['genres']=df['genres'].str.replace('\\|6 separate stories','')\n",
    "    df['genres']=df['genres'].str.replace(' \\(30min\\)','')\n",
    "    df['genres']=df['genres'].str.replace(' (road bicycle racing)','')\n",
    "    df['genres']=df['genres'].str.replace(' v-cinema','')\n",
    "    df['genres']=df['genres'].str.replace('tv miniseries','tv_miniseries')\n",
    "    df['genres']=df['genres'].str.replace('\\|docudrama','\\|documentary|drama')\n",
    "    df['genres']=df['genres'].str.replace(' in animation','|animation')\n",
    "    df['genres']=df['genres'].str.replace('((adaptation).+)','')\n",
    "    df['genres']=df['genres'].str.replace('((adaptated).+)','')\n",
    "    df['genres']=df['genres'].str.replace('((adapted).+)','')\n",
    "    df['genres']=df['genres'].str.replace('(( on ).+)','')\n",
    "    df['genres']=df['genres'].str.replace('american football','sports')\n",
    "    df['genres']=df['genres'].str.replace('dev\\|nusrat jahan','sports')\n",
    "    df['genres']=df['genres'].str.replace('television miniseries','tv_miniseries')\n",
    "    df['genres']=df['genres'].str.replace(' \\(artistic\\)','')\n",
    "    df['genres']=df['genres'].str.replace(' \\|direct-to-dvd','')\n",
    "    df['genres']=df['genres'].str.replace('history dram','history drama')\n",
    "    df['genres']=df['genres'].str.replace('martial art','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('psycho thriller,','psycho thriller')\n",
    "    df['genres']=df['genres'].str.replace('\\|1 girl\\|3 suitors','')\n",
    "    df['genres']=df['genres'].str.replace(' \\(road bicycle racing\\)','')\n",
    "    filterE = df['genres']==\"ero\"\n",
    "    df.loc[filterE,'genres']=\"adult\"\n",
    "    filterE = df['genres']==\"music\"\n",
    "    df.loc[filterE,'genres']=\"musical\"\n",
    "    filterE = df['genres']==\"-\"\n",
    "    df.loc[filterE,'genres']=''\n",
    "    filterE = df['genres']==\"comedy–drama\"\n",
    "    df.loc[filterE,'genres'] = \"comedy|drama\"\n",
    "    filterE = df['genres']==\"comedy–horror\"\n",
    "    df.loc[filterE,'genres'] = \"comedy|horror\"\n",
    "    df['genres']=df['genres'].str.replace(' ','|')\n",
    "    df['genres']=df['genres'].str.replace(',','|')\n",
    "    df['genres']=df['genres'].str.replace('-','')\n",
    "    df['genres']=df['genres'].str.replace('actionadventure','action|adventure')\n",
    "    df['genres']=df['genres'].str.replace('actioncomedy','action|comedy')\n",
    "    df['genres']=df['genres'].str.replace('actiondrama','action|drama')\n",
    "    df['genres']=df['genres'].str.replace('actionlove','action|love')\n",
    "    df['genres']=df['genres'].str.replace('actionmasala','action|masala')\n",
    "    df['genres']=df['genres'].str.replace('actionchildren','action|children')\n",
    "    df['genres']=df['genres'].str.replace('fantasychildren\\|','fantasy|children')\n",
    "    df['genres']=df['genres'].str.replace('fantasycomedy','fantasy|comedy')\n",
    "    df['genres']=df['genres'].str.replace('fantasyperiod','fantasy|period')\n",
    "    df['genres']=df['genres'].str.replace('cbctv_miniseries','tv_miniseries')\n",
    "    df['genres']=df['genres'].str.replace('dramacomedy','drama|comedy')\n",
    "    df['genres']=df['genres'].str.replace('dramacomedysocial','drama|comedy|social')\n",
    "    df['genres']=df['genres'].str.replace('dramathriller','drama|thriller')\n",
    "    df['genres']=df['genres'].str.replace('comedydrama','comedy|drama')\n",
    "    df['genres']=df['genres'].str.replace('dramathriller','drama|thriller')\n",
    "    df['genres']=df['genres'].str.replace('comedyhorror','comedy|horror')\n",
    "    df['genres']=df['genres'].str.replace('sciencefiction','science_fiction')\n",
    "    df['genres']=df['genres'].str.replace('adventurecomedy','adventure|comedy')\n",
    "    df['genres']=df['genres'].str.replace('animationdrama','animation|drama')\n",
    "    df['genres']=df['genres'].str.replace('\\|\\|','|')\n",
    "    df['genres']=df['genres'].str.replace('muslim','religious')\n",
    "    df['genres']=df['genres'].str.replace('thriler','thriller')\n",
    "    df['genres']=df['genres'].str.replace('crimethriller','crime|thriller')\n",
    "    df['genres']=df['genres'].str.replace('fantay','fantasy')\n",
    "    df['genres']=df['genres'].str.replace('actionthriller','action|thriller')\n",
    "    df['genres']=df['genres'].str.replace('comedysocial','comedy|social')\n",
    "    df['genres']=df['genres'].str.replace('martialarts','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('\\|\\(children\\|poker\\|karuta\\)','')\n",
    "    df['genres']=df['genres'].str.replace('epichistory','epic|history')\n",
    "    df['genres']=df['genres'].str.replace('erotica','adult')\n",
    "    df['genres']=df['genres'].str.replace('erotic','adult')\n",
    "    df['genres']=df['genres'].str.replace('((\\|produced\\|).+)','')\n",
    "    df['genres']=df['genres'].str.replace('chanbara','chambara')\n",
    "    df['genres']=df['genres'].str.replace('comedythriller','comedy|thriller')\n",
    "    df['genres']=df['genres'].str.replace('biblical','religious')\n",
    "    df['genres']=df['genres'].str.replace('biblical','religious')\n",
    "    df['genres']=df['genres'].str.replace('colour\\|yellow\\|productions\\|eros\\|international','')\n",
    "    df['genres']=df['genres'].str.replace('\\|directtodvd','')\n",
    "    df['genres']=df['genres'].str.replace('liveaction','live|action')\n",
    "    df['genres']=df['genres'].str.replace('melodrama','drama')\n",
    "    df['genres']=df['genres'].str.replace('superheroes','superheroe')\n",
    "    df['genres']=df['genres'].str.replace('gangsterthriller','gangster|thriller')\n",
    "    df['genres']=df['genres'].str.replace('heistcomedy','comedy')\n",
    "    df['genres']=df['genres'].str.replace('heist','action')\n",
    "    df['genres']=df['genres'].str.replace('historic','history')\n",
    "    df['genres']=df['genres'].str.replace('historydisaster','history|disaster')\n",
    "    df['genres']=df['genres'].str.replace('warcomedy','war|comedy')\n",
    "    df['genres']=df['genres'].str.replace('westerncomedy','western|comedy')\n",
    "    df['genres']=df['genres'].str.replace('ancientcostume','costume')\n",
    "    df['genres']=df['genres'].str.replace('computeranimation','animation')\n",
    "    df['genres']=df['genres'].str.replace('dramatic','drama')\n",
    "    df['genres']=df['genres'].str.replace('familya','family')\n",
    "    df['genres']=df['genres'].str.replace('familya','family')\n",
    "    df['genres']=df['genres'].str.replace('dramedy','drama|comedy')\n",
    "    df['genres']=df['genres'].str.replace('dramaa','drama')\n",
    "    df['genres']=df['genres'].str.replace('famil\\|','family')\n",
    "    df['genres']=df['genres'].str.replace('superheroe','superhero')\n",
    "    df['genres']=df['genres'].str.replace('biogtaphy','biography')\n",
    "    df['genres']=df['genres'].str.replace('devotionalbiography','devotional|biography')\n",
    "    df['genres']=df['genres'].str.replace('docufiction','documentary|fiction')\n",
    "    df['genres']=df['genres'].str.replace('familydrama','family|drama')\n",
    "    df['genres']=df['genres'].str.replace('espionage','spy')\n",
    "    df['genres']=df['genres'].str.replace('supeheroes','superhero')\n",
    "    df['genres']=df['genres'].str.replace('romancefiction','romance|fiction')\n",
    "    df['genres']=df['genres'].str.replace('horrorthriller','horror|thriller')\n",
    "    df['genres']=df['genres'].str.replace('suspensethriller','suspense|thriller')\n",
    "    df['genres']=df['genres'].str.replace('musicaliography','musical|biography')\n",
    "    df['genres']=df['genres'].str.replace('triller','thriller')\n",
    "    df['genres']=df['genres'].str.replace('\\|\\(fiction\\)','|fiction')\n",
    "    df['genres']=df['genres'].str.replace('romanceaction','romance|action')\n",
    "    df['genres']=df['genres'].str.replace('romancecomedy','romance|comedy')\n",
    "    df['genres']=df['genres'].str.replace('romancehorror','romance|horror')\n",
    "    df['genres']=df['genres'].str.replace('romcom','romance|comedy')\n",
    "    df['genres']=df['genres'].str.replace('rom\\|com','romance|comedy')\n",
    "    df['genres']=df['genres'].str.replace('satirical','satire')\n",
    "    df['genres']=df['genres'].str.replace('science_fictionchildren','science_fiction|children')\n",
    "    df['genres']=df['genres'].str.replace('homosexual','adult')\n",
    "    df['genres']=df['genres'].str.replace('sexual','adult')\n",
    "    df['genres']=df['genres'].str.replace('mockumentary','documentary')\n",
    "    df['genres']=df['genres'].str.replace('periodic','period')\n",
    "    df['genres']=df['genres'].str.replace('romanctic','romantic')\n",
    "    df['genres']=df['genres'].str.replace('politics','political')\n",
    "    df['genres']=df['genres'].str.replace('samurai','martial_arts')\n",
    "    df['genres']=df['genres'].str.replace('tv_miniseries','series')\n",
    "    df['genres']=df['genres'].str.replace('serial','series')\n",
    "    filterE = df['genres']==\"musical–comedy\"\n",
    "    df.loc[filterE,'genres'] = \"musical|comedy\"\n",
    "    filterE = df['genres']==\"roman|porno\"\n",
    "    df.loc[filterE,'genres'] = \"adult\"\n",
    "    filterE = df['genres']==\"action—masala\"\n",
    "    df.loc[filterE,'genres'] = \"action|masala\"\n",
    "    filterE = df['genres']==\"horror–thriller\"\n",
    "    df.loc[filterE,'genres'] = \"horror|thriller\"\n",
    "    df['genres']=df['genres'].str.replace('family','children')\n",
    "    df['genres']=df['genres'].str.replace('martial_arts','action')\n",
    "    df['genres']=df['genres'].str.replace('horror','thriller')\n",
    "    df['genres']=df['genres'].str.replace('war','action')\n",
    "    df['genres']=df['genres'].str.replace('adventure','action')\n",
    "    df['genres']=df['genres'].str.replace('science_fiction','action')\n",
    "    df['genres']=df['genres'].str.replace('western','action')\n",
    "    df['genres']=df['genres'].str.replace('western','action')\n",
    "    df['genres']=df['genres'].str.replace('spy','action')\n",
    "    df['genres']=df['genres'].str.replace('superhero','action')\n",
    "    df['genres']=df['genres'].str.replace('social','')\n",
    "    df['genres']=df['genres'].str.replace('suspense','action')\n",
    "    filterE = df['genres']==\"drama|romance|adult|children\"\n",
    "    df.loc[filterE,'genres'] = \"drama|romance|adult\"\n",
    "    df['genres']=df['genres'].str.replace('\\|–\\|','|')\n",
    "    df['genres']=df['genres'].str.strip(to_strip='\\|')\n",
    "    df['genres']=df['genres'].str.replace('actionner','action')\n",
    "    df['genres']=df['genres'].str.strip()\n",
    "\n",
    "def format_input_text(row):\n",
    "    \"\"\"\n",
    "    Create a robust input text by labeling different parts of the input.\n",
    "    Handles null values gracefully by excluding empty fields.\n",
    "    \"\"\"\n",
    "    fields = [\n",
    "        f\"release_year: {row['Release Year']}\" if pd.notna(row['Release Year']) else \"\",\n",
    "        f\"title: {row['Title']}\" if pd.notna(row['Title']) else \"\",\n",
    "        f\"origin: {row['Origin/Ethnicity']}\" if pd.notna(row['Origin/Ethnicity']) else \"\",\n",
    "        f\"director: {row['Director']}\" if pd.notna(row['Director']) else \"\",\n",
    "        f\"cast: {row['Cast']}\" if pd.notna(row['Cast']) else \"\",\n",
    "        f\"plot: {row['Plot']}\" if pd.notna(row['Plot']) else \"\",\n",
    "    ]\n",
    "    return \" | \".join(filter(None, fields))\n",
    "\n",
    "def filter_genres(genres, include_list):\n",
    "    filtered_genres = [genre for genre in genres if genre in include_list]\n",
    "    return filtered_genres if filtered_genres else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(\"wiki_movie_plots_deduped.csv\")\n",
    "genre_cleanup(movie_df)\n",
    "\n",
    "movie_df['genre_array']=movie_df['genres'].str.split('|')\n",
    "movie_df['genre_array']= movie_df['genre_array'].apply(np.sort).apply(np.unique)\n",
    "movie_df = movie_df[movie_df['genres']!='']\n",
    "\n",
    "movie_df['genre_array']=movie_df['genres'].str.split('|')\n",
    "movie_df['genre_array']= movie_df['genre_array'].apply(np.sort).apply(np.unique)\n",
    "movie_df = movie_df[movie_df['genres']!='']\n",
    "\n",
    "kept_genres = [\n",
    "    'drama','comedy','action','thriller','romance','crime','musical','animation','children'\n",
    "]\n",
    "\n",
    "movie_df[\"genre_array\"] = movie_df[\"genre_array\"].apply(lambda genres: filter_genres(genres, kept_genres))\n",
    "movie_df = movie_df.dropna(subset=[\"genre_array\"])\n",
    "\n",
    "movie_df[\"formatted_text\"] = movie_df.apply(format_input_text, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list = movie_df[\"genre_array\"].tolist()\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(genres_list)\n",
    "labels = torch.tensor(genre_matrix, dtype=torch.float)\n",
    "\n",
    "model_id = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenized_data = tokenizer(\n",
    "    movie_df[\"formatted_text\"].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "dataset = TensorDataset(\n",
    "    tokenized_data[\"input_ids\"],\n",
    "    tokenized_data[\"attention_mask\"],\n",
    "    labels\n",
    ")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1330/1330 [40:47<00:00,  1.84s/it, avg_loss=0.31, grad_norm=1.16e+5, loss=0.289]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -> loss: 0.309908046903915 train_f1: 0.3944\n",
      "Epoch 1 -> test_f11: 0.5646\n",
      " New best model found. Saving checkpoint with test_f1=0.5646.\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1330/1330 [15:11<00:00,  1.46it/s, avg_loss=0.206, grad_norm=2.26e+5, loss=0.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -> loss: 0.2059716706157179 train_f1: 0.6598\n",
      "Epoch 2 -> test_f11: 0.6419\n",
      " New best model found. Saving checkpoint with test_f1=0.6419.\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1330/1330 [11:00<00:00,  2.01it/s, avg_loss=0.171, grad_norm=2.68e+5, loss=0.205]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -> loss: 0.17148629242092148 train_f1: 0.7340\n",
      "Epoch 3 -> test_f11: 0.6519\n",
      " New best model found. Saving checkpoint with test_f1=0.6519.\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = int(0.1 * total_steps)  # 10% of total steps as warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", leave=True)\n",
    "    for batch_index, batch in enumerate(progress_bar):\n",
    "        input_ids, attention_mask, labels = [b.to('cuda') for b in batch]\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                grad_norm += p.grad.data.norm(2).item() ** 2\n",
    "        grad_norm = grad_norm ** 0.5\n",
    "        scaler.step(optimizer) \n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        labels_cpu = labels.detach().cpu().numpy()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels_cpu)\n",
    "\n",
    "        avg_loss = total_loss / (batch_index + 1)\n",
    "        progress_bar.set_postfix(loss=loss.item(), avg_loss=avg_loss, grad_norm=grad_norm)\n",
    "\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_preds_bin = (all_preds >= 0.5).astype(int)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds_bin, average=\"micro\")\n",
    "    print(f\"Epoch {epoch + 1} -> loss: {total_loss / len(train_dataloader)} train_f1: {epoch_f1:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, labels = [t.to('cuda') for t in batch]\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "            \n",
    "            preds = torch.sigmoid(logits).cpu().numpy()\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    val_preds = np.concatenate(val_preds, axis=0)\n",
    "    val_labels = np.concatenate(val_labels, axis=0)\n",
    "    val_preds_bin = (val_preds >= 0.5).astype(int)\n",
    "    val_f1 = f1_score(val_labels, val_preds_bin, average=\"micro\")\n",
    "    print(f\"Epoch {epoch + 1} -> test_f1: {val_f1:.4f}\")\n",
    "\n",
    "    # Checkpoint if best\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        print(f\" New best model found. Saving checkpoint with test_f1={val_f1:.4f}.\")\n",
    "        model.save_pretrained(\"bert_best_model\")\n",
    "        tokenizer.save_pretrained(\"bert_best_tokenizer\")\n",
    "    \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test F1: 0.6519\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.75      0.70      0.72      1223\n",
      "   animation       0.87      0.66      0.75       195\n",
      "    children       0.67      0.05      0.09       129\n",
      "      comedy       0.76      0.60      0.67      1427\n",
      "       crime       0.59      0.34      0.43       325\n",
      "       drama       0.68      0.69      0.69      1863\n",
      "     musical       0.70      0.41      0.51       190\n",
      "     romance       0.61      0.41      0.49       493\n",
      "    thriller       0.73      0.56      0.64       670\n",
      "\n",
      "   micro avg       0.72      0.60      0.65      6515\n",
      "   macro avg       0.71      0.49      0.55      6515\n",
      "weighted avg       0.71      0.60      0.64      6515\n",
      " samples avg       0.67      0.64      0.64      6515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = AutoModelForSequenceClassification.from_pretrained(\"bert_best_model\").to('cuda')\n",
    "best_model.eval()\n",
    "\n",
    "test_preds = []\n",
    "test_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids, attention_mask, labels = [t.to('cuda') for t in batch]\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = best_model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        preds = torch.sigmoid(logits).cpu().numpy()\n",
    "        test_preds.append(preds)\n",
    "        test_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_labels_list = np.concatenate(test_labels_list, axis=0)\n",
    "test_preds_bin = (test_preds >= 0.5).astype(int)\n",
    "\n",
    "test_f1 = f1_score(test_labels_list, test_preds_bin, average=\"micro\")\n",
    "print(f\"\\nFinal Test F1: {test_f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(\n",
    "    test_labels_list,\n",
    "    test_preds_bin,\n",
    "    target_names=mlb.classes_,\n",
    "    zero_division=0.0\n",
    ")\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Text: release_year: 2026 | title: The Oath | origin: British | director: Greta Gerwig | cast: Anya Taylor-Joy, Andrew Garfield, Daniel Kaluuya, Helena Bonham Carter | plot: A young heiress joins forces with a rogue investigator to expose a hidden society of aristocrats involved in a series of crimes.\n",
      "Predicted Labels: ['action (0.6157)', 'thriller (0.5293)']\n"
     ]
    }
   ],
   "source": [
    "text_to_classify = \"\\\n",
    "release_year: 2026 \\\n",
    "| title: The Oath \\\n",
    "| origin: British \\\n",
    "| director: Greta Gerwig \\\n",
    "| cast: Anya Taylor-Joy, Andrew Garfield, Daniel Kaluuya, Helena Bonham Carter \\\n",
    "| plot: A young heiress joins forces with a rogue investigator to expose a hidden society of aristocrats involved in a series of crimes.\"\n",
    "\n",
    "inputs = tokenizer(text_to_classify, return_tensors=\"pt\", truncation=True).to('cuda')\n",
    "\n",
    "with autocast(device_type='cuda'), torch.no_grad():\n",
    "    logits = best_model(**inputs).logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "predicted_labels = [str(mlb.classes_[i]) + ' (' + str(p) + ')' for i, p in enumerate(probs) if p >= 0.5]\n",
    "print(f\"Dummy Text: {text_to_classify}\")\n",
    "print(f\"Predicted Labels: {predicted_labels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3_11_8_ml_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
